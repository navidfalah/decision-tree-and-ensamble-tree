# -*- coding: utf-8 -*-
"""ensembels_decision_tree.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1euxNNJjt1eVquEGWFVKpelZ9NDi9uFvp
"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.datasets import make_moons
from sklearn.model_selection import train_test_split


X, y = make_moons(n_samples=10000, noise=0.25, random_state=42)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

forest = RandomForestClassifier(n_estimators=100, random_state=42)
forest.fit(X_train, y_train).score(X_test, y_test)

!pip install mglearn

import mglearn
import matplotlib.pyplot as plt


fig, axes = plt.subplots(2, 3, figsize=(20, 10))

for i, (ax, tree) in enumerate(zip(axes.ravel(), forest.estimators_)):
    ax.set_title(f"Tree {i+1}")
    mglearn.plots.plot_tree_partition(X_train, y_train, tree, ax=ax)

mglearn.plots.plot_2d_separator(forest, X_train, fill=True, ax=axes[-1, -1], alpha=.4)
axes[-1, -1].set_title("Random Forest")
mglearn.discrete_scatter(X_train[:, 0], X_train[:, 1], y_train)
plt.show()

#### another random forest for the breast cancer
from sklearn.datasets import load_breast_cancer
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split

cancer = load_breast_cancer()

X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, test_size=0.2, random_state=0)

forest = RandomForestClassifier(n_estimators=100, random_state=0)
forest.fit(X_train, y_train).score(X_test, y_test), forest.score(X_train, y_train)

## feature importance
import numpy as np

def plot_feature_importances_cancer(model):
    n_features = cancer.data.shape[1]
    plt.barh(range(n_features), model.feature_importances_, align='center')
    plt.yticks(np.arange(n_features), cancer.feature_names)
    plt.xlabel("Feature importance")
    plt.ylabel("Feature")
    plt.show()

plot_feature_importances_cancer(forest)

### gradian boosted regression tree (gradient boosting machines)
from sklearn.ensemble import GradientBoostingClassifier

X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, random_state=0)

gbrt = GradientBoostingClassifier(random_state=0)
gbrt.fit(X_train, y_train)
gbrt.score(X_test, y_test), gbrt.score(X_train, y_train)

pre_pruning = GradientBoostingClassifier(random_state=0, max_depth=1)
pre_pruning.fit(X_train, y_train)
pre_pruning.score(X_test, y_test), pre_pruning.score(X_train, y_train)

pre_pruning.feature_importances_

### learning rate

lr = GradientBoostingClassifier(random_state=0, learning_rate=0.01)
lr.fit(X_train, y_train)
lr.score(X_test, y_test), lr.score(X_train, y_train)

plot_feature_importances_cancer(pre_pruning)

